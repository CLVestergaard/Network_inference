{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prop_type(value, key=None):\n",
    "    \"\"\"\n",
    "    Performs typing and value conversion for the graph_tool PropertyMap class.\n",
    "    If a key is provided, it also ensures the key is in a format that can be\n",
    "    used with the PropertyMap. Returns a tuple, (type name, value, key).\n",
    "\n",
    "    This function is adapted from Benjamin Bengfort's blog post!\n",
    "    https://bbengfort.github.io/2016/06/graph-tool-from-networkx/\n",
    "    \"\"\"\n",
    "    if isinstance(key, str):  # Keep the key as a string\n",
    "        key = key  # No encoding necessary in Python 3\n",
    "\n",
    "    # Deal with the value\n",
    "    if isinstance(value, bool):\n",
    "        tname = 'bool'\n",
    "\n",
    "    elif isinstance(value, int):\n",
    "        tname = 'float'\n",
    "        value = float(value)\n",
    "\n",
    "    elif isinstance(value, float):\n",
    "        tname = 'float'\n",
    "\n",
    "    elif isinstance(value, str):\n",
    "        tname = 'string'\n",
    "        \n",
    "    elif isinstance(value, bytes):\n",
    "        tname = 'bytes'\n",
    "\n",
    "    elif isinstance(value, dict):\n",
    "        tname = 'object'\n",
    "\n",
    "    else:\n",
    "        tname = 'string'\n",
    "        value = str(value)\n",
    "\n",
    "    return tname, value, key\n",
    "\n",
    "\n",
    "def nx2gt(nxG):\n",
    "    \"\"\"\n",
    "    Converts a networkx graph to a graph-tool graph.\n",
    "    \"\"\"\n",
    "    # Phase 0: Create a directed or undirected graph-tool Graph\n",
    "    gtG = gt.Graph(directed=nxG.is_directed())\n",
    "\n",
    "    # Add the Graph properties as \"internal properties\"\n",
    "    for key, value in nxG.graph.items():\n",
    "        # Convert the value and key into a type for graph-tool\n",
    "        tname, value, key = get_prop_type(value, key)\n",
    "\n",
    "        prop = gtG.new_graph_property(tname) # Create the PropertyMap\n",
    "        gtG.graph_properties[key] = prop     # Set the PropertyMap\n",
    "        gtG.graph_properties[key] = value    # Set the actual value\n",
    "\n",
    "    # Phase 1: Add the vertex and edge property maps\n",
    "    # Go through all nodes and edges and add seen properties\n",
    "    # Add the node properties first\n",
    "    nprops = set() # cache keys to only add properties once\n",
    "    for node, data in nxG.nodes(data=True):\n",
    "\n",
    "        # Go through all the properties if not seen and add them.\n",
    "        for key, val in data.items():\n",
    "            if key in nprops: continue # Skip properties already added\n",
    "\n",
    "            # Convert the value and key into a type for graph-tool\n",
    "            tname, _, key  = get_prop_type(val, key)\n",
    "\n",
    "            prop = gtG.new_vertex_property(tname) # Create the PropertyMap\n",
    "            gtG.vertex_properties[key] = prop     # Set the PropertyMap\n",
    "\n",
    "            # Add the key to the already seen properties\n",
    "            nprops.add(key)\n",
    "\n",
    "    # Also add the node id: in NetworkX a node can be any hashable type, but\n",
    "    # in graph-tool node are defined as indices. So we capture any strings\n",
    "    # in a special PropertyMap called 'id' -- modify as needed!\n",
    "    gtG.vertex_properties['id'] = gtG.new_vertex_property('string')\n",
    "\n",
    "    # Add the edge properties second\n",
    "    eprops = set() # cache keys to only add properties once\n",
    "    for src, dst, data in nxG.edges(data=True):\n",
    "\n",
    "        # Go through all the edge properties if not seen and add them.\n",
    "        for key, val in data.items():\n",
    "            if key in eprops: continue # Skip properties already added\n",
    "\n",
    "            # Convert the value and key into a type for graph-tool\n",
    "            tname, _, key = get_prop_type(val, key)\n",
    "\n",
    "            prop = gtG.new_edge_property(tname) # Create the PropertyMap\n",
    "            gtG.edge_properties[key] = prop     # Set the PropertyMap\n",
    "\n",
    "            # Add the key to the already seen properties\n",
    "            eprops.add(key)\n",
    "\n",
    "    # Phase 2: Actually add all the nodes and vertices with their properties\n",
    "    # Add the nodes\n",
    "    vertices = {} # vertex mapping for tracking edges later\n",
    "    for node, data in nxG.nodes(data=True):\n",
    "\n",
    "        # Create the vertex and annotate for our edges later\n",
    "        v = gtG.add_vertex()\n",
    "        vertices[node] = v\n",
    "\n",
    "        # Set the vertex properties, not forgetting the id property\n",
    "        data['id'] = str(node)\n",
    "        for key, value in data.items():\n",
    "            gtG.vp[key][v] = value # vp is short for vertex_properties\n",
    "\n",
    "    # Add the edges\n",
    "    for src, dst, data in nxG.edges(data=True):\n",
    "\n",
    "        # Look up the vertex structs from our vertices mapping and add edge.\n",
    "        e = gtG.add_edge(vertices[src], vertices[dst])\n",
    "\n",
    "        # Add the edge properties\n",
    "        for key, value in data.items():\n",
    "            gtG.ep[key][e] = value # ep is short for edge_properties\n",
    "\n",
    "    # Done, finally!\n",
    "    return gtG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Erdos-Renyi example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "p = 0.01\n",
    "\n",
    "G = nx.erdos_renyi_graph(N,p)\n",
    "g = nx2gt(G)\n",
    "\n",
    "state = gt.minimize_blockmodel_dl(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = state.entropy()\n",
    "\n",
    "for i in range(1000): # this should be sufficiently large\n",
    "    state.multiflip_mcmc_sweep(beta=np.inf, niter=10)\n",
    "\n",
    "S2 = state.entropy()\n",
    "\n",
    "print(\"Improvement:\", S2 - S1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating blockmodel networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "def create_graph_from_e(N, e):\n",
    "    \"\"\"\n",
    "    Creates a graph with N nodes and assigns edges based on a predefined \n",
    "    edge budget matrix e1, where the nodes are divided into three blocks.\n",
    "\n",
    "    The adjacency matrix `e1` specifies the number of edges to add between \n",
    "    each pair of blocks. Nodes are partitioned equally into three groups, \n",
    "    and edges are randomly assigned between and within these groups based \n",
    "    on the values in `e1`.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    N : int\n",
    "        The total number of nodes in the graph. This should be divisible by 3 \n",
    "        for an equal partitioning of nodes into three groups.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    G : networkx.Graph\n",
    "        A graph object where nodes are partitioned into three groups and edges \n",
    "        are added based on the edge budget matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a graph with N nodes\n",
    "    G = nx.MultiGraph()\n",
    "    G.add_nodes_from(list(range(N)))\n",
    "\n",
    "    # Define partition for the nodes\n",
    "    num_blocks = len(e)\n",
    "    partition = []\n",
    "    for b in range(num_blocks):\n",
    "        partition = partition + [b]*int(N/num_blocks)\n",
    "    \n",
    "    if len(partition)!=N:\n",
    "        add_nodes = N-len(partition)\n",
    "        for _ in range(add_nodes):\n",
    "            partition.append(partition[-1])\n",
    "\n",
    "    # Loop over the blocks in the partition    \n",
    "    for block_i in range(e.shape[0]):\n",
    "        for block_j in range(e.shape[1]):\n",
    "\n",
    "            # Get nodes belonging to block i and block j            \n",
    "            nodes_i = [ix for ix,i in enumerate(partition) if i==block_i]\n",
    "            nodes_j = [ix for ix,i in enumerate(partition) if i==block_j]\n",
    "            \n",
    "            # Get the number of edges to add between blocks\n",
    "            budget_edges = e[block_i, block_j]\n",
    "            \n",
    "            # Create all possible edges between nodes in block_i and block_j\n",
    "            possible_edges = np.array(list(it.product(nodes_i, nodes_j)))\n",
    "            \n",
    "            # Randomly select edges based on the budget\n",
    "            selected_edges_inds = np.random.choice(\n",
    "                list(range(len(possible_edges))),\n",
    "                size=budget_edges,\n",
    "                replace=True # allow repeat edges?\n",
    "                # replace=False  # Ensure no repeated edges\n",
    "            )\n",
    "            selected_edges = possible_edges[selected_edges_inds]\n",
    "\n",
    "            # Add the selected edges to the graph\n",
    "            G.add_edges_from(selected_edges)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ii = 0.925\n",
    "p_ij = (1-p_ii)/2\n",
    "block_matrix1 = np.array([[p_ii, p_ij, p_ij], \n",
    "                          [p_ij, p_ii, p_ij], \n",
    "                          [p_ij, p_ij, p_ii]])\n",
    "\n",
    "p_ii = 0.5\n",
    "p_ij = (1-p_ii)/2\n",
    "block_matrix2 = np.array([[p_ii, p_ij, p_ij], \n",
    "                          [p_ij, p_ii, p_ij], \n",
    "                          [p_ij, p_ij, p_ii]])\n",
    "\n",
    "p_ii = 0.3333\n",
    "p_ij = (1-p_ii)/2\n",
    "block_matrix3 = np.array([[p_ii, p_ij, p_ij], \n",
    "                          [p_ij, p_ii, p_ij], \n",
    "                          [p_ij, p_ij, p_ii]])\n",
    "\n",
    "p_ii = 0.025\n",
    "p_ij = (1-p_ii)/2\n",
    "block_matrix4 = np.array([[p_ii, p_ij, p_ij], \n",
    "                          [p_ij, p_ii, p_ij], \n",
    "                          [p_ij, p_ij, p_ii]])\n",
    "\n",
    "plot_blocks = [block_matrix1, block_matrix2, block_matrix3, block_matrix4]\n",
    "pii_list = [0.925, 0.5, 0.3333, 0.025]\n",
    "\n",
    "fig, ax = plt.subplots(1,4,figsize=(10,2),dpi=200)\n",
    "\n",
    "for i,b in enumerate(plot_blocks):\n",
    "    ax[i].imshow(b, vmin=0, vmax=1, cmap='Greys')\n",
    "    ax[i].set_title('Block matrix\\n'+r\"$p_{ii} = %.3f$\"%(pii_list[i]))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for viz purposes, create a layout of the graph we want\n",
    "N = 150\n",
    "Gz = nx.ring_of_cliques(3, int(N/3))\n",
    "pos = nx.kamada_kawai_layout(Gz)\n",
    "\n",
    "\n",
    "#  matrix of edge counts between blocks\n",
    "e1 = np.array([[500, 50, 50], \n",
    "               [50, 500, 50], \n",
    "               [50, 50, 500]])\n",
    "\n",
    "e2 = np.array([[650, 50, 10], \n",
    "               [50, 700, 100], \n",
    "               [10, 100, 130]])\n",
    "\n",
    "e3 = np.array([[200, 200, 200], \n",
    "               [200, 200, 200], \n",
    "               [200, 200, 200]])\n",
    "\n",
    "e4 = np.array([[10, 600, 50], \n",
    "               [10, 10, 620], \n",
    "               [50, 400, 50]])\n",
    "\n",
    "plot_blocks = [e1,e2,e3,e4]\n",
    "\n",
    "fig, ax = plt.subplots(2,4,figsize=(14,8),dpi=200)\n",
    "\n",
    "Gs = []\n",
    "\n",
    "for x, block_matrix_x in enumerate(plot_blocks):\n",
    "\n",
    "    Gx = create_graph_from_e(N, block_matrix_x)\n",
    "    Gs.append(Gx)\n",
    "    Aij = nx.to_numpy_array(Gx)\n",
    "\n",
    "    ax[(0,x)].imshow(Aij, vmin=0, vmax=1)\n",
    "    ax[(0,x)].set_title('Total number of edges:\\n'+r\"$M = %i$\"%(Gx.number_of_edges()))\n",
    "\n",
    "    nx.draw(Gx, pos=pos, node_size=10, width=0.25, edge_color='.6', ax=ax[(1,x)])\n",
    "\n",
    "plt.suptitle('Microcanonical approach to SMBs', y=0.965, fontweight='bold', fontsize='xx-large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First optimize using greedy heuristic, then sample using MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, Gx in enumerate(Gs):\n",
    "    gx = nx2gt(Gx)\n",
    "    state = gt.minimize_blockmodel_dl(gx)\n",
    "    \n",
    "    S1 = state.entropy()\n",
    "\n",
    "    for i in range(1000): # this should be sufficiently large\n",
    "        state.multiflip_mcmc_sweep(beta=np.inf, niter=10)\n",
    "\n",
    "    S2 = state.entropy()\n",
    "\n",
    "    print(\"Improvement SMB\", n, \":\", S2 - S1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-world network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gt.collection.data[\"celegansneural\"]\n",
    "\n",
    "state = gt.minimize_nested_blockmodel_dl(g)\n",
    "\n",
    "S1 = state.entropy()\n",
    "\n",
    "for i in range(1000): # this should be sufficiently large\n",
    "    state.multiflip_mcmc_sweep(beta=np.inf, niter=10)\n",
    "\n",
    "S2 = state.entropy()\n",
    "\n",
    "print(\"Improvement:\", S2 - S1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gt.collection.data[\"celegansneural\"]\n",
    "\n",
    "state = gt.minimize_nested_blockmodel_dl(g)\n",
    "\n",
    "gt.mcmc_anneal(state, beta_range=(1, 10), niter=1000, mcmc_equilibrate_args=dict(force_niter=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3 = state.entropy()\n",
    "\n",
    "print(\"Further improvement:\", S3 - S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from the posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gt.collection.data[\"lesmis\"]\n",
    "\n",
    "state = gt.BlockState(g)   # This automatically initializes the state with a partition\n",
    "                           # into one group. The user could also pass a higher number\n",
    "                           # to start with a random partition of a given size, or pass a\n",
    "                           # specific initial partition using the 'b' parameter.\n",
    "\n",
    "# Now we run 1,000 sweeps of the MCMC. Note that the number of groups\n",
    "# is allowed to change, so it will eventually move from the initial\n",
    "# value of B=1 to whatever is most appropriate for the data.\n",
    "\n",
    "dS, nattempts, nmoves = state.multiflip_mcmc_sweep(niter=1000)\n",
    "\n",
    "print(\"Change in description length:\", dS)\n",
    "print(\"Number of accepted vertex moves:\", nmoves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will accept equilibration if 10 sweeps are completed without a\n",
    "# record breaking event, 2 consecutive times.\n",
    "\n",
    "gt.mcmc_equilibrate(state, wait=10, nbreaks=2, mcmc_args=dict(niter=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first equilibrate the Markov chain\n",
    "gt.mcmc_equilibrate(state, wait=1000, mcmc_args=dict(niter=10))\n",
    "\n",
    "bs = [] # collect some partitions\n",
    "\n",
    "def collect_partitions(s):\n",
    "   global bs\n",
    "   bs.append(s.b.a.copy())\n",
    "\n",
    "# Now we collect partitions for exactly 100,000 sweeps, at intervals\n",
    "# of 10 sweeps:\n",
    "gt.mcmc_equilibrate(state, force_niter=10000, mcmc_args=dict(niter=10),\n",
    "                    callback=collect_partitions)\n",
    "\n",
    "# Disambiguate partitions and obtain marginals\n",
    "pmode = gt.PartitionModeState(bs, converge=True)\n",
    "pv = pmode.get_marginal(g)\n",
    "\n",
    "# Now the node marginals are stored in property map pv. We can\n",
    "# visualize them as pie charts on the nodes:\n",
    "state.draw(pos=g.vp.pos, vertex_shape=\"pie\", vertex_pie_fractions=pv,\n",
    "           output=\"lesmis-sbm-marginals.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.zeros(g.num_vertices() + 1)\n",
    "\n",
    "def collect_num_groups(s):\n",
    "    B = s.get_nonempty_B()\n",
    "    h[B] += 1\n",
    "\n",
    "# Now we collect partitions for exactly 100,000 sweeps, at intervals\n",
    "# of 10 sweeps:\n",
    "gt.mcmc_equilibrate(state, force_niter=10000, mcmc_args=dict(niter=10),\n",
    "                    callback=collect_num_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heirarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gt.collection.data[\"lesmis\"]\n",
    "\n",
    "state = gt.NestedBlockState(g)   # By default this creates a state with an initial single-group\n",
    "                                 # hierarchy of depth ceil(log2(g.num_vertices()).\n",
    "\n",
    "# Now we run 1000 sweeps of the MCMC\n",
    "\n",
    "dS, nmoves = 0, 0\n",
    "for i in range(100):\n",
    "    ret = state.multiflip_mcmc_sweep(niter=10)\n",
    "    dS += ret[0]\n",
    "    nmoves += ret[1]\n",
    "\n",
    "print(\"Change in description length:\", dS)\n",
    "print(\"Number of accepted vertex moves:\", nmoves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first equilibrate the Markov chain\n",
    "gt.mcmc_equilibrate(state, wait=1000, mcmc_args=dict(niter=10))\n",
    "\n",
    "# collect nested partitions\n",
    "bs = []\n",
    "\n",
    "def collect_partitions(s):\n",
    "   global bs\n",
    "   bs.append(s.get_bs())\n",
    "\n",
    "# Now we collect the marginals for exactly 100,000 sweeps\n",
    "gt.mcmc_equilibrate(state, force_niter=10000, mcmc_args=dict(niter=10),\n",
    "                    callback=collect_partitions)\n",
    "\n",
    "# Disambiguate partitions and obtain marginals\n",
    "pmode = gt.PartitionModeState(bs, nested=True, converge=True)\n",
    "pv = pmode.get_marginal(g)\n",
    "\n",
    "# Get consensus estimate\n",
    "bs = pmode.get_max_nested()\n",
    "\n",
    "state = state.copy(bs=bs)\n",
    "\n",
    "# We can visualize the marginals as pie charts on the nodes:\n",
    "state.draw(vertex_shape=\"pie\", vertex_pie_fractions=pv,\n",
    "           output=\"lesmis-nested-sbm-marginals.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [np.zeros(g.num_vertices() + 1) for s in state.get_levels()]\n",
    "\n",
    "def collect_num_groups(s):\n",
    "    for l, sl in enumerate(s.get_levels()):\n",
    "       B = sl.get_nonempty_B()\n",
    "       h[l][B] += 1\n",
    "\n",
    "# Now we collect the marginal distribution for exactly 100,000 sweeps\n",
    "gt.mcmc_equilibrate(state, force_niter=10000, mcmc_args=dict(niter=10),\n",
    "                    callback=collect_num_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for j in range(100):\n",
    "        state.multiflip_mcmc_sweep(niter=10)\n",
    "    state.draw(output=\"lesmis-partition-sample-%i.svg\" % i, empty_branches=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modes of the posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gt.collection.data[\"lesmis\"]\n",
    "\n",
    "state = gt.NestedBlockState(g)\n",
    "\n",
    "# Equilibration\n",
    "gt.mcmc_equilibrate(state, force_niter=1000, mcmc_args=dict(niter=10))\n",
    "\n",
    "bs = []\n",
    "\n",
    "def collect_partitions(s):\n",
    "   global bs\n",
    "   bs.append(s.get_bs())\n",
    "\n",
    "# We will collect only partitions 1000 partitions. For more accurate\n",
    "# results, this number should be increased.\n",
    "gt.mcmc_equilibrate(state, force_niter=1000, mcmc_args=dict(niter=10),\n",
    "                    callback=collect_partitions)\n",
    "\n",
    "# Infer partition modes\n",
    "pmode = gt.ModeClusterState(bs, nested=True)\n",
    "\n",
    "# Minimize the mode state itself\n",
    "gt.mcmc_equilibrate(pmode, wait=1, mcmc_args=dict(niter=1, beta=np.inf))\n",
    "\n",
    "# Get inferred modes\n",
    "modes = pmode.get_modes()\n",
    "\n",
    "for i, mode in enumerate(modes):\n",
    "    b = mode.get_max_nested()    # mode's maximum\n",
    "    pv = mode.get_marginal(g)    # mode's marginal distribution\n",
    "\n",
    "    print(f\"Mode {i} with size {mode.get_M()/len(bs)}\")\n",
    "    state = state.copy(bs=b)\n",
    "    state.draw(vertex_shape=\"pie\", vertex_pie_fractions=pv,\n",
    "               output=\"lesmis-partition-mode-%i.svg\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
